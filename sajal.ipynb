{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9398a86f-c1ea-4cf6-bc23-77a4ec8474a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High CLV Segment Summary:\n",
      "       avg_order_value  purchase_frequency  avg_time_between_purchases\n",
      "count     19998.000000        19998.000000                19998.000000\n",
      "mean       3176.952903            9.382438                    0.007782\n",
      "std         246.166221            3.120115                   24.746933\n",
      "min        2899.451111            1.000000                 -308.000000\n",
      "25%        2991.877227            7.000000                  -13.053571\n",
      "50%        3109.423722            9.000000                    0.000000\n",
      "75%        3293.784554           11.000000                   13.000000\n",
      "max        4825.260000           23.000000                  343.000000\n",
      "\n",
      "Low CLV Segment Summary:\n",
      "       avg_order_value  purchase_frequency  avg_time_between_purchases\n",
      "count     19998.000000        19998.000000                19998.000000\n",
      "mean       1821.622082            9.340584                    0.014351\n",
      "std         246.410298            3.101710                   25.713323\n",
      "min          43.200000            1.000000                 -290.000000\n",
      "25%        1703.680040            7.000000                  -13.200000\n",
      "50%        1887.140873            9.000000                    0.000000\n",
      "75%        2009.052242           11.000000                   13.440476\n",
      "max        2101.554286           24.000000                  335.000000\n",
      "\n",
      "Customer Segments and CLV:\n",
      "   user_id           CLV  avg_order_value  purchase_frequency  \\\n",
      "0        1  79816.429807      2660.255000                  14   \n",
      "1        2  59740.748405      1991.139231                  13   \n",
      "2        3  53810.544160      1793.487500                   8   \n",
      "3        4  70785.993602      2359.273571                  14   \n",
      "4        5  81692.886217      2722.796667                   9   \n",
      "\n",
      "   avg_time_between_purchases    segment  \n",
      "0                   -7.153846  Upper-Mid  \n",
      "1                  -16.916667        Low  \n",
      "2                   -7.428571        Low  \n",
      "3                    4.461538  Lower-Mid  \n",
      "4                  -33.000000  Upper-Mid  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the orders dataset\n",
    "df_orders = pd.read_csv(\"orders__table.csv\")\n",
    "\n",
    "# Convert 'order_date' to datetime format for further analysis\n",
    "df_orders['order_date'] = pd.to_datetime(df_orders['order_date'])\n",
    "\n",
    "# --- Step 1: Calculate Purchase Frequency, Average Order Value, and Time Between Purchases ---\n",
    "\n",
    "# Group by user_id to get total revenue and number of purchases per customer\n",
    "customer_revenue = df_orders.groupby('user_id')['order_value'].sum()  # Total revenue per customer\n",
    "purchase_frequency = df_orders.groupby('user_id')['order_id'].count()  # Number of orders per customer\n",
    "\n",
    "# Average Purchase Value\n",
    "avg_order_value = customer_revenue / purchase_frequency\n",
    "\n",
    "# Calculate time between purchases (days) for each user\n",
    "df_orders['previous_order'] = df_orders.groupby('user_id')['order_date'].shift(1)\n",
    "df_orders['time_between'] = (df_orders['order_date'] - df_orders['previous_order']).dt.days\n",
    "avg_time_between_purchases = df_orders.groupby('user_id')['time_between'].mean().fillna(0)  # Fill first purchase NaN with 0\n",
    "\n",
    "# --- Step 2: CLV Calculation ---\n",
    "\n",
    "# Average Purchase Frequency Rate (for all customers)\n",
    "avg_purchase_frequency = purchase_frequency.mean()\n",
    "\n",
    "# Placeholder for Average Customer Lifespan (set as 3 years, or calculate if churn data is available)\n",
    "avg_customer_lifespan = 3\n",
    "\n",
    "# Customer Value = Average Purchase Value * Purchase Frequency Rate * Customer Lifespan\n",
    "customer_value = avg_order_value * avg_purchase_frequency * avg_customer_lifespan\n",
    "\n",
    "# Create a DataFrame for CLV and customer behavior metrics\n",
    "df_clv = pd.DataFrame({\n",
    "    'user_id': customer_value.index,\n",
    "    'CLV': customer_value,\n",
    "    'avg_order_value': avg_order_value,\n",
    "    'purchase_frequency': purchase_frequency,\n",
    "    'avg_time_between_purchases': avg_time_between_purchases\n",
    "}).reset_index(drop=True)\n",
    "\n",
    "# --- Step 3: Segment Customers Based on CLV ---\n",
    "\n",
    "# Segment customers into 5 groups based on CLV\n",
    "df_clv['segment'] = pd.qcut(df_clv['CLV'], 5, labels=['Low', 'Lower-Mid', 'Mid', 'Upper-Mid', 'High'])\n",
    "\n",
    "# --- Step 4: Analyze Behavior Based on Segments ---\n",
    "\n",
    "# Analyze the behaviors of high CLV vs. low CLV segments\n",
    "high_clv_segment = df_clv[df_clv['segment'] == 'High']\n",
    "low_clv_segment = df_clv[df_clv['segment'] == 'Low']\n",
    "\n",
    "# Print summary statistics for high CLV segment\n",
    "print(\"High CLV Segment Summary:\")\n",
    "print(high_clv_segment[['avg_order_value', 'purchase_frequency', 'avg_time_between_purchases']].describe())\n",
    "\n",
    "# Print summary statistics for low CLV segment\n",
    "print(\"\\nLow CLV Segment Summary:\")\n",
    "print(low_clv_segment[['avg_order_value', 'purchase_frequency', 'avg_time_between_purchases']].describe())\n",
    "\n",
    "# Display the first few rows of the segmented data\n",
    "print(\"\\nCustomer Segments and CLV:\")\n",
    "print(df_clv.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cb1e7d6-46f7-4488-a95b-951b28e5340c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>CLV</th>\n",
       "      <th>avg_order_value</th>\n",
       "      <th>purchase_frequency</th>\n",
       "      <th>avg_time_between_purchases</th>\n",
       "      <th>segment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>79816.429807</td>\n",
       "      <td>2660.255000</td>\n",
       "      <td>14</td>\n",
       "      <td>-7.153846</td>\n",
       "      <td>Upper-Mid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>59740.748405</td>\n",
       "      <td>1991.139231</td>\n",
       "      <td>13</td>\n",
       "      <td>-16.916667</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>53810.544160</td>\n",
       "      <td>1793.487500</td>\n",
       "      <td>8</td>\n",
       "      <td>-7.428571</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70785.993602</td>\n",
       "      <td>2359.273571</td>\n",
       "      <td>14</td>\n",
       "      <td>4.461538</td>\n",
       "      <td>Lower-Mid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>81692.886217</td>\n",
       "      <td>2722.796667</td>\n",
       "      <td>9</td>\n",
       "      <td>-33.000000</td>\n",
       "      <td>Upper-Mid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99984</th>\n",
       "      <td>99996</td>\n",
       "      <td>78957.045275</td>\n",
       "      <td>2631.612000</td>\n",
       "      <td>10</td>\n",
       "      <td>-8.222222</td>\n",
       "      <td>Upper-Mid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99985</th>\n",
       "      <td>99997</td>\n",
       "      <td>103718.971587</td>\n",
       "      <td>3456.918750</td>\n",
       "      <td>8</td>\n",
       "      <td>-10.428571</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99986</th>\n",
       "      <td>99998</td>\n",
       "      <td>65470.719961</td>\n",
       "      <td>2182.117273</td>\n",
       "      <td>11</td>\n",
       "      <td>16.200000</td>\n",
       "      <td>Lower-Mid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99987</th>\n",
       "      <td>99999</td>\n",
       "      <td>73821.520367</td>\n",
       "      <td>2460.446667</td>\n",
       "      <td>12</td>\n",
       "      <td>-12.818182</td>\n",
       "      <td>Mid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99988</th>\n",
       "      <td>100000</td>\n",
       "      <td>91102.133735</td>\n",
       "      <td>3036.403750</td>\n",
       "      <td>8</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99989 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id            CLV  avg_order_value  purchase_frequency  \\\n",
       "0            1   79816.429807      2660.255000                  14   \n",
       "1            2   59740.748405      1991.139231                  13   \n",
       "2            3   53810.544160      1793.487500                   8   \n",
       "3            4   70785.993602      2359.273571                  14   \n",
       "4            5   81692.886217      2722.796667                   9   \n",
       "...        ...            ...              ...                 ...   \n",
       "99984    99996   78957.045275      2631.612000                  10   \n",
       "99985    99997  103718.971587      3456.918750                   8   \n",
       "99986    99998   65470.719961      2182.117273                  11   \n",
       "99987    99999   73821.520367      2460.446667                  12   \n",
       "99988   100000   91102.133735      3036.403750                   8   \n",
       "\n",
       "       avg_time_between_purchases    segment  \n",
       "0                       -7.153846  Upper-Mid  \n",
       "1                      -16.916667        Low  \n",
       "2                       -7.428571        Low  \n",
       "3                        4.461538  Lower-Mid  \n",
       "4                      -33.000000  Upper-Mid  \n",
       "...                           ...        ...  \n",
       "99984                   -8.222222  Upper-Mid  \n",
       "99985                  -10.428571       High  \n",
       "99986                   16.200000  Lower-Mid  \n",
       "99987                  -12.818182        Mid  \n",
       "99988                  -10.000000       High  \n",
       "\n",
       "[99989 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8af3db3-b5cd-43ee-9ed4-90e209eb2d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlations with CLV:\n",
      "user_id                       0.002902\n",
      "avg_order_value               1.000000\n",
      "purchase_frequency            0.002165\n",
      "avg_time_between_purchases    0.000595\n",
      "quantity                      0.002739\n",
      "order_value                   1.000000\n",
      "Negative feedback             0.000544\n",
      "Neutral feedback              0.000097\n",
      "Positive feedback            -0.001092\n",
      "Name: CLV, dtype: float64\n",
      "   user_id           CLV  avg_order_value  purchase_frequency  \\\n",
      "0        1  79816.429807      2660.255000                  14   \n",
      "1        2  59740.748405      1991.139231                  13   \n",
      "2        3  53810.544160      1793.487500                   8   \n",
      "3        4  70785.993602      2359.273571                  14   \n",
      "4        5  81692.886217      2722.796667                   9   \n",
      "\n",
      "   avg_time_between_purchases    segment  quantity  order_value  \\\n",
      "0                   -7.153846  Upper-Mid  0.254365     0.329780   \n",
      "1                  -16.916667        Low  0.356303    -1.045432   \n",
      "2                   -7.428571        Low -0.714044    -1.451659   \n",
      "3                    4.461538  Lower-Mid  1.171806    -0.288817   \n",
      "4                  -33.000000  Upper-Mid -0.663075     0.458320   \n",
      "\n",
      "   Negative feedback  Neutral feedback  Positive feedback  \n",
      "0           0.715514         -0.587202          -0.299287  \n",
      "1          -1.397596         -0.587202           3.341274  \n",
      "2           0.715514         -0.587202          -0.299287  \n",
      "3           0.715514         -0.587202          -0.299287  \n",
      "4           0.715514         -0.587202          -0.299287  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load datasets\n",
    "df_clicks = pd.read_csv(\"clicks__data.csv\")\n",
    "df_views = pd.read_csv(\"views__data.csv\")\n",
    "df_orders = pd.read_csv(\"orders__table.csv\")\n",
    "\n",
    "# Calculate CLV if not already done\n",
    "# df_clv = ... (Ensure df_clv is calculated as before)\n",
    "\n",
    "# Calculate additional engagement metrics\n",
    "# 1. Calculate total quantity purchased and average order value per user\n",
    "quantity_summary = df_orders.groupby('user_id')['quantity'].sum().reset_index()\n",
    "avg_order_value_summary = df_orders.groupby('user_id')['order_value'].mean().reset_index()\n",
    "\n",
    "# 2. Calculate average feedback score if applicable (assuming feedback can be quantified)\n",
    "# Here we assume feedback is categorical, you may need to apply text analysis if feedback is textual\n",
    "feedback_summary = df_orders.groupby('user_id')['feedback'].apply(lambda x: x.value_counts().idxmax()).reset_index()\n",
    "\n",
    "# Merge these metrics with CLV data\n",
    "df_clv_engagement = df_clv.merge(quantity_summary, on='user_id', how='left')\n",
    "df_clv_engagement = df_clv_engagement.merge(avg_order_value_summary, on='user_id', how='left')\n",
    "df_clv_engagement = df_clv_engagement.merge(feedback_summary, on='user_id', how='left')\n",
    "\n",
    "# Fill missing values\n",
    "df_clv_engagement['quantity'] = df_clv_engagement['quantity'].fillna(0)\n",
    "df_clv_engagement['order_value'] = df_clv_engagement['order_value'].fillna(0)\n",
    "df_clv_engagement['feedback'] = df_clv_engagement['feedback'].fillna('No Feedback')\n",
    "\n",
    "# Convert feedback to numeric if it's categorical\n",
    "feedback_dummies = pd.get_dummies(df_clv_engagement['feedback'])\n",
    "df_clv_engagement = pd.concat([df_clv_engagement, feedback_dummies], axis=1)\n",
    "df_clv_engagement.drop('feedback', axis=1, inplace=True)\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(df_clv_engagement[['quantity', 'order_value'] + list(feedback_dummies.columns)])\n",
    "\n",
    "# Add scaled features to the dataframe\n",
    "df_clv_engagement[['quantity', 'order_value'] + list(feedback_dummies.columns)] = scaled_features\n",
    "\n",
    "# Calculate correlation matrix\n",
    "# Only numeric columns should be used for correlation analysis\n",
    "numeric_df = df_clv_engagement.select_dtypes(include=['float64', 'int64'])\n",
    "correlation_matrix = numeric_df.corr()\n",
    "clv_correlations = correlation_matrix['CLV'].drop('CLV')\n",
    "\n",
    "# Print correlations\n",
    "print(\"Correlations with CLV:\")\n",
    "print(clv_correlations)\n",
    "\n",
    "# Display first few rows of the final data with additional metrics\n",
    "print(df_clv_engagement.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6af2809d-5ec1-44c3-ae5c-5546bb696e04",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load data\n",
    "df_orders = pd.read_csv(\"orders__table.csv\")\n",
    "df_clicks = pd.read_csv(\"clicks__data.csv\")\n",
    "df_views = pd.read_csv(\"views__data.csv\")\n",
    "\n",
    "# Example merging based on user_id\n",
    "df_combined = pd.merge(df_orders, df_clicks, on='user_id', how='left')\n",
    "df_combined = pd.merge(df_combined, df_views, on='user_id', how='left')\n",
    "\n",
    "# Feature Engineering\n",
    "# Calculate total clicks and views per user\n",
    "df_combined['total_clicks'] = df_combined.groupby('user_id')['clicks'].transform('sum')\n",
    "df_combined['total_views'] = df_combined.groupby('user_id')['views'].transform('sum')\n",
    "\n",
    "# Calculate average order value and total quantity per user\n",
    "df_combined['avg_order_value'] = df_combined.groupby('user_id')['order_value'].transform('mean')\n",
    "df_combined['total_quantity'] = df_combined.groupby('user_id')['quantity'].transform('sum')\n",
    "\n",
    "# Convert categorical feedback to numerical values (one-hot encoding)\n",
    "feedback_dummies = pd.get_dummies(df_combined['feedback'], prefix='feedback')\n",
    "df_combined = pd.concat([df_combined, feedback_dummies], axis=1)\n",
    "\n",
    "# Drop original categorical columns and rows with NaNs\n",
    "df_combined = df_combined.drop(columns=['order_date', 'feedback'])\n",
    "df_combined = df_combined.dropna()\n",
    "\n",
    "# Analyze correlation between new features and CLV\n",
    "correlation_matrix = df_combined.corr()\n",
    "clv_correlations = correlation_matrix['CLV'].drop('CLV')\n",
    "\n",
    "# Print correlations\n",
    "print(\"Correlations with CLV (including new features):\")\n",
    "print(clv_correlations)\n",
    "\n",
    "# Example feature importance using a Random Forest model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Prepare features and target variable\n",
    "X = df_combined.drop(['CLV', 'user_id'], axis=1)\n",
    "y = df_combined['CLV']\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train a Random Forest model\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Model Score on Test Set:\", model.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c98048f-42c5-4ca0-bcaa-1306292dee49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   click_id  user_id        date  clicks_count\n",
      "0         0    14225  2023-09-26             1\n",
      "1         1    19369  2024-09-08            11\n",
      "2         2      339  2024-03-08            44\n",
      "3         3    19310  2023-11-26            37\n",
      "4         4    13523  2023-11-20            10\n",
      "        click_id  user_id        date  clicks_count\n",
      "100000    100000    76454  2023-11-09             3\n",
      "100001    100001    31295  2024-08-14             5\n",
      "100002    100002    35044  2023-10-31             3\n",
      "100003    100003    95250  2023-10-06             0\n",
      "100004    100004    18969  2024-08-06             1\n",
      "        click_id  user_id        date  clicks_count\n",
      "200000    200000    16272  2024-03-13            26\n",
      "200001    200001    65056  2023-09-22            21\n",
      "200002    200002    82719  2024-07-30             8\n",
      "200003    200003    20775  2023-11-03             1\n",
      "200004    200004    54687  2024-03-31            18\n",
      "        click_id  user_id        date  clicks_count\n",
      "300000    300000    94156  2024-02-13            19\n",
      "300001    300001    14641  2023-11-29             1\n",
      "300002    300002    10474  2024-03-18             1\n",
      "300003    300003    61422  2024-04-07             8\n",
      "300004    300004    17826  2023-10-23             6\n",
      "        click_id  user_id        date  clicks_count\n",
      "400000    400000    82349  2024-03-22             8\n",
      "400001    400001    82077  2024-01-24             2\n",
      "400002    400002    67733  2024-09-09            45\n",
      "400003    400003    45041  2023-09-30             4\n",
      "400004    400004    95771  2024-03-15            16\n",
      "        click_id  user_id        date  clicks_count\n",
      "500000    500000    53292  2023-09-13            13\n",
      "500001    500001    43282  2024-06-15             6\n",
      "500002    500002    75240  2024-07-24             2\n",
      "500003    500003    77385  2023-12-13            10\n",
      "500004    500004    33988  2024-05-04             0\n",
      "        click_id  user_id        date  clicks_count\n",
      "600000    600000     7002  2024-08-30            10\n",
      "600001    600001    88804  2024-01-16            20\n",
      "600002    600002    15275  2024-08-25             9\n",
      "600003    600003    12666  2024-08-02             6\n",
      "600004    600004    29432  2023-10-08             5\n",
      "        click_id  user_id        date  clicks_count\n",
      "700000    700000    11825  2023-10-26            24\n",
      "700001    700001    46733  2024-06-27            16\n",
      "700002    700002    53190  2024-07-07             0\n",
      "700003    700003    24998  2023-10-24             3\n",
      "700004    700004    13753  2024-01-11             0\n",
      "        click_id  user_id        date  clicks_count\n",
      "800000    800000    45884  2023-11-02            15\n",
      "800001    800001     3103  2024-01-07             1\n",
      "800002    800002    79307  2024-06-21             4\n",
      "800003    800003    45643  2024-05-03             1\n",
      "800004    800004    32153  2023-10-03             5\n",
      "        click_id  user_id        date  clicks_count\n",
      "900000    900000    90379  2024-08-05             5\n",
      "900001    900001     8662  2023-09-22            26\n",
      "900002    900002    18512  2024-09-10            25\n",
      "900003    900003    13723  2024-04-26             1\n",
      "900004    900004    87517  2024-01-20             3\n",
      "   view_id  user_id        date  app_open_count\n",
      "0        0    14225  2023-09-26               4\n",
      "1        1    19369  2024-09-08              46\n",
      "2        2      339  2024-03-08              48\n",
      "3        3    19310  2023-11-26              42\n",
      "4        4    13523  2023-11-20              19\n",
      "        view_id  user_id        date  app_open_count\n",
      "100000   100000    76454  2023-11-09               7\n",
      "100001   100001    31295  2024-08-14               8\n",
      "100002   100002    35044  2023-10-31               6\n",
      "100003   100003    95250  2023-10-06               3\n",
      "100004   100004    18969  2024-08-06               6\n",
      "        view_id  user_id        date  app_open_count\n",
      "200000   200000    16272  2024-03-13              43\n",
      "200001   200001    65056  2023-09-22              41\n",
      "200002   200002    82719  2024-07-30              28\n",
      "200003   200003    20775  2023-11-03               2\n",
      "200004   200004    54687  2024-03-31              33\n",
      "        view_id  user_id        date  app_open_count\n",
      "300000   300000    94156  2024-02-13              32\n",
      "300001   300001    14641  2023-11-29               5\n",
      "300002   300002    10474  2024-03-18              28\n",
      "300003   300003    61422  2024-04-07              34\n",
      "300004   300004    17826  2023-10-23              30\n",
      "        view_id  user_id        date  app_open_count\n",
      "400000   400000    82349  2024-03-22              27\n",
      "400001   400001    82077  2024-01-24               9\n",
      "400002   400002    67733  2024-09-09              48\n",
      "400003   400003    45041  2023-09-30              33\n",
      "400004   400004    95771  2024-03-15              39\n",
      "        view_id  user_id        date  app_open_count\n",
      "500000   500000    53292  2023-09-13              48\n",
      "500001   500001    43282  2024-06-15              42\n",
      "500002   500002    75240  2024-07-24              45\n",
      "500003   500003    77385  2023-12-13              16\n",
      "500004   500004    33988  2024-05-04               1\n",
      "        view_id  user_id        date  app_open_count\n",
      "600000   600000     7002  2024-08-30              11\n",
      "600001   600001    88804  2024-01-16              26\n",
      "600002   600002    15275  2024-08-25              25\n",
      "600003   600003    12666  2024-08-02              26\n",
      "600004   600004    29432  2023-10-08              11\n",
      "        view_id  user_id        date  app_open_count\n",
      "700000   700000    11825  2023-10-26              38\n",
      "700001   700001    46733  2024-06-27              35\n",
      "700002   700002    53190  2024-07-07               1\n",
      "700003   700003    24998  2023-10-24              15\n",
      "700004   700004    13753  2024-01-11               1\n",
      "        view_id  user_id        date  app_open_count\n",
      "800000   800000    45884  2023-11-02              29\n",
      "800001   800001     3103  2024-01-07               9\n",
      "800002   800002    79307  2024-06-21              48\n",
      "800003   800003    45643  2024-05-03               5\n",
      "800004   800004    32153  2023-10-03              16\n",
      "        view_id  user_id        date  app_open_count\n",
      "900000   900000    90379  2024-08-05               6\n",
      "900001   900001     8662  2023-09-22              27\n",
      "900002   900002    18512  2024-09-10              49\n",
      "900003   900003    13723  2024-04-26               2\n",
      "900004   900004    87517  2024-01-20               9\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "chunk_size = 100000  # Adjust the chunk size as needed\n",
    "\n",
    "# Process clicks data in chunks\n",
    "chunks_clicks = pd.read_csv(\"clicks__data.csv\", chunksize=chunk_size)\n",
    "for chunk in chunks_clicks:\n",
    "    # Process each chunk here\n",
    "    print(chunk.head())\n",
    "\n",
    "# Similarly, process views data\n",
    "chunks_views = pd.read_csv(\"views__data.csv\", chunksize=chunk_size)\n",
    "for chunk in chunks_views:\n",
    "    # Process each chunk here\n",
    "    print(chunk.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b458e592-3c69-45cf-bc7c-6181670a4bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orders = pd.read_csv(\"orders__table.csv\", dtype={'order_id': 'int32', 'user_id': 'int32', 'quantity': 'int32', 'supplier_id': 'int32'})\n",
    "df_clicks = pd.read_csv(\"clicks__data.csv\", dtype={'user_id': 'int32'})\n",
    "df_views = pd.read_csv(\"views__data.csv\", dtype={'user_id': 'int32'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98a535fd-dae5-496f-852f-f39bca749fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "chunk_size = 100000  # Adjust the chunk size as needed\n",
    "\n",
    "# Initialize a list to store aggregated chunks\n",
    "aggregated_clicks_chunks = []\n",
    "\n",
    "# Process clicks data in chunks\n",
    "chunks_clicks = pd.read_csv(\"clicks__data.csv\", chunksize=chunk_size)\n",
    "for chunk in chunks_clicks:\n",
    "    # Aggregate click counts by user_id\n",
    "    aggregated_chunk = chunk.groupby('user_id')['clicks_count'].sum().reset_index()\n",
    "    aggregated_chunk.columns = ['user_id', 'total_clicks']\n",
    "    aggregated_clicks_chunks.append(aggregated_chunk)\n",
    "\n",
    "# Combine results from all chunks\n",
    "df_clicks_aggregated = pd.concat(aggregated_clicks_chunks).groupby('user_id').sum().reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0cb73b1-1fbb-4fd0-aa5b-e949dcdfe4f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id  total_clicks\n",
      "0        1           188\n",
      "1        2           151\n",
      "2        3           125\n",
      "3        4           204\n",
      "4        5            39\n"
     ]
    }
   ],
   "source": [
    "print(df_clicks_aggregated.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "81b25a81-1a24-4aa9-8c54-461eb11bf831",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 100000  # Adjust the chunk size as needed\n",
    "\n",
    "# Initialize a list to store aggregated chunks\n",
    "aggregated_views_chunks = []\n",
    "\n",
    "# Process views data in chunks\n",
    "chunks_views = pd.read_csv(\"views__data.csv\", chunksize=chunk_size)\n",
    "for chunk in chunks_views:\n",
    "    # Aggregate view counts by user_id\n",
    "    aggregated_chunk = chunk.groupby('user_id')['app_open_count'].sum().reset_index()\n",
    "    aggregated_chunk.columns = ['user_id', 'total_views']\n",
    "    aggregated_views_chunks.append(aggregated_chunk)\n",
    "\n",
    "# Combine results from all chunks\n",
    "df_views_aggregated = pd.concat(aggregated_views_chunks).groupby('user_id').sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "02c6b7b6-7966-4234-86ce-95e58a61d847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a list to store aggregated chunks\n",
    "aggregated_orders_chunks = []\n",
    "\n",
    "# Process orders data in chunks\n",
    "chunks_orders = pd.read_csv(\"orders__table.csv\", chunksize=chunk_size)\n",
    "for chunk in chunks_orders:\n",
    "    # Aggregate order values by user_id\n",
    "    aggregated_chunk = chunk.groupby('user_id').agg({\n",
    "        'order_value': 'sum',\n",
    "        'quantity': 'sum'\n",
    "    }).reset_index()\n",
    "    aggregated_chunk.columns = ['user_id', 'total_order_value', 'total_quantity']\n",
    "    aggregated_orders_chunks.append(aggregated_chunk)\n",
    "\n",
    "# Combine results from all chunks\n",
    "df_orders_aggregated = pd.concat(aggregated_orders_chunks).groupby('user_id').sum().reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f48728c6-d424-44fa-aea8-640067c9ce1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge aggregated clicks with aggregated orders\n",
    "df_combined = pd.merge(df_orders_aggregated, df_clicks_aggregated, on='user_id', how='left')\n",
    "\n",
    "# Merge the result with aggregated views\n",
    "df_combined = pd.merge(df_combined, df_views_aggregated, on='user_id', how='left')\n",
    "\n",
    "# Fill NaN values if necessary\n",
    "df_combined.fillna(0, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3598ed1b-b74f-4918-bcb9-d95193184095",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average order value per user\n",
    "df_combined['avg_order_value'] = df_combined['total_order_value'] / df_combined['total_quantity']\n",
    "\n",
    "# Example: Calculate click-to-order ratio\n",
    "df_combined['click_to_order_ratio'] = df_combined['total_clicks'] / (df_combined['total_order_value'] + 1)  # Avoid division by zero\n",
    "\n",
    "# Example: Calculate view-to-click ratio\n",
    "df_combined['view_to_click_ratio'] = df_combined['total_views'] / (df_combined['total_clicks'] + 1)  # Avoid division by zero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b0688ad4-882d-4665-88d6-9b0fbe0c9483",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined.to_csv(\"combined_data.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c12a55d2-9fae-4594-92cf-ad56ce289c84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             user_id  total_order_value  total_quantity  total_clicks  \\\n",
      "count   99989.000000       99989.000000    99989.000000  99989.000000   \n",
      "mean    50001.759854       25004.073788       55.009401    117.655792   \n",
      "std     28867.344313        9149.604543       19.619902     50.812032   \n",
      "min         1.000000          43.200000        1.000000      0.000000   \n",
      "25%     25004.000000       18489.630000       41.000000     81.000000   \n",
      "50%     50002.000000       24361.880000       54.000000    113.000000   \n",
      "75%     75000.000000       30824.760000       68.000000    149.000000   \n",
      "max    100000.000000       70527.120000      164.000000    400.000000   \n",
      "\n",
      "        total_views  avg_order_value  click_to_order_ratio  \\\n",
      "count  99989.000000     99989.000000          99989.000000   \n",
      "mean     245.017282       470.251979              0.004921   \n",
      "std       89.760266       134.739763              0.002739   \n",
      "min        1.000000         7.200000              0.000000   \n",
      "25%      181.000000       382.505385              0.003606   \n",
      "50%      239.000000       454.900000              0.004656   \n",
      "75%      302.000000       538.511026              0.005887   \n",
      "max      696.000000      4736.450000              0.588235   \n",
      "\n",
      "       view_to_click_ratio  \n",
      "count         99989.000000  \n",
      "mean              2.205569  \n",
      "std               0.702288  \n",
      "min               1.000000  \n",
      "25%               1.791946  \n",
      "50%               2.066667  \n",
      "75%               2.439560  \n",
      "max              51.000000  \n"
     ]
    }
   ],
   "source": [
    "print(df_combined.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dda25936-8df2-4d84-97fd-046b602c6cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined['CLV'] = df_combined['total_order_value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "66aed348-d582-474f-a9bb-69d0ae3991c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>total_order_value</th>\n",
       "      <th>total_quantity</th>\n",
       "      <th>total_clicks</th>\n",
       "      <th>total_views</th>\n",
       "      <th>avg_order_value</th>\n",
       "      <th>click_to_order_ratio</th>\n",
       "      <th>view_to_click_ratio</th>\n",
       "      <th>CLV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>37243.57</td>\n",
       "      <td>60</td>\n",
       "      <td>188</td>\n",
       "      <td>427</td>\n",
       "      <td>620.726167</td>\n",
       "      <td>0.005048</td>\n",
       "      <td>2.259259</td>\n",
       "      <td>37243.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>25884.81</td>\n",
       "      <td>62</td>\n",
       "      <td>151</td>\n",
       "      <td>278</td>\n",
       "      <td>417.496935</td>\n",
       "      <td>0.005833</td>\n",
       "      <td>1.828947</td>\n",
       "      <td>25884.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>14347.90</td>\n",
       "      <td>41</td>\n",
       "      <td>125</td>\n",
       "      <td>215</td>\n",
       "      <td>349.948780</td>\n",
       "      <td>0.008711</td>\n",
       "      <td>1.706349</td>\n",
       "      <td>14347.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>33029.83</td>\n",
       "      <td>78</td>\n",
       "      <td>204</td>\n",
       "      <td>414</td>\n",
       "      <td>423.459359</td>\n",
       "      <td>0.006176</td>\n",
       "      <td>2.019512</td>\n",
       "      <td>33029.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>24505.17</td>\n",
       "      <td>42</td>\n",
       "      <td>39</td>\n",
       "      <td>123</td>\n",
       "      <td>583.456429</td>\n",
       "      <td>0.001591</td>\n",
       "      <td>3.075000</td>\n",
       "      <td>24505.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99984</th>\n",
       "      <td>99996</td>\n",
       "      <td>26316.12</td>\n",
       "      <td>51</td>\n",
       "      <td>118</td>\n",
       "      <td>280</td>\n",
       "      <td>516.002353</td>\n",
       "      <td>0.004484</td>\n",
       "      <td>2.352941</td>\n",
       "      <td>26316.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99985</th>\n",
       "      <td>99997</td>\n",
       "      <td>27655.35</td>\n",
       "      <td>52</td>\n",
       "      <td>81</td>\n",
       "      <td>193</td>\n",
       "      <td>531.833654</td>\n",
       "      <td>0.002929</td>\n",
       "      <td>2.353659</td>\n",
       "      <td>27655.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99986</th>\n",
       "      <td>99998</td>\n",
       "      <td>24003.29</td>\n",
       "      <td>46</td>\n",
       "      <td>175</td>\n",
       "      <td>344</td>\n",
       "      <td>521.810652</td>\n",
       "      <td>0.007290</td>\n",
       "      <td>1.954545</td>\n",
       "      <td>24003.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99987</th>\n",
       "      <td>99999</td>\n",
       "      <td>29525.36</td>\n",
       "      <td>71</td>\n",
       "      <td>209</td>\n",
       "      <td>346</td>\n",
       "      <td>415.850141</td>\n",
       "      <td>0.007078</td>\n",
       "      <td>1.647619</td>\n",
       "      <td>29525.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99988</th>\n",
       "      <td>100000</td>\n",
       "      <td>24291.23</td>\n",
       "      <td>41</td>\n",
       "      <td>71</td>\n",
       "      <td>185</td>\n",
       "      <td>592.469024</td>\n",
       "      <td>0.002923</td>\n",
       "      <td>2.569444</td>\n",
       "      <td>24291.23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99989 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id  total_order_value  total_quantity  total_clicks  total_views  \\\n",
       "0            1           37243.57              60           188          427   \n",
       "1            2           25884.81              62           151          278   \n",
       "2            3           14347.90              41           125          215   \n",
       "3            4           33029.83              78           204          414   \n",
       "4            5           24505.17              42            39          123   \n",
       "...        ...                ...             ...           ...          ...   \n",
       "99984    99996           26316.12              51           118          280   \n",
       "99985    99997           27655.35              52            81          193   \n",
       "99986    99998           24003.29              46           175          344   \n",
       "99987    99999           29525.36              71           209          346   \n",
       "99988   100000           24291.23              41            71          185   \n",
       "\n",
       "       avg_order_value  click_to_order_ratio  view_to_click_ratio       CLV  \n",
       "0           620.726167              0.005048             2.259259  37243.57  \n",
       "1           417.496935              0.005833             1.828947  25884.81  \n",
       "2           349.948780              0.008711             1.706349  14347.90  \n",
       "3           423.459359              0.006176             2.019512  33029.83  \n",
       "4           583.456429              0.001591             3.075000  24505.17  \n",
       "...                ...                   ...                  ...       ...  \n",
       "99984       516.002353              0.004484             2.352941  26316.12  \n",
       "99985       531.833654              0.002929             2.353659  27655.35  \n",
       "99986       521.810652              0.007290             1.954545  24003.29  \n",
       "99987       415.850141              0.007078             1.647619  29525.36  \n",
       "99988       592.469024              0.002923             2.569444  24291.23  \n",
       "\n",
       "[99989 rows x 9 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "71bacdee-729b-4040-8be2-aa49ab27803c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id                -0.003383\n",
      "total_order_value       1.000000\n",
      "total_quantity          0.767945\n",
      "total_clicks            0.635752\n",
      "total_views             0.746605\n",
      "avg_order_value         0.277234\n",
      "click_to_order_ratio   -0.214781\n",
      "view_to_click_ratio    -0.070835\n",
      "Name: CLV, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "correlation_matrix = df_combined.corr()\n",
    "clv_correlations = correlation_matrix['CLV'].drop('CLV')\n",
    "print(clv_correlations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995cd89e-ed3b-40a6-8e6f-7cdd9400c19b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
